\documentclass[12pt, a4paper]{article}
\usepackage[english, croatian]{babel}
\usepackage{authblk}
\usepackage{listings}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{commath}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{amsfonts}

\usepackage{subfig}
\usepackage{float}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage[%
colorlinks=true,
pdfborder={0 0 0},
linkcolor=red
]{hyperref}

\begin{document}
\date{}
\title{RI-GAN}
\author{Kosta Grujčić, Momčilo Knežević}
\affil{Matematički fakultet }
\maketitle

\begin{abstract}
\end{abstract}

\section{Uvod}

\section{\textit{Related Work}}
U ovom poglavlju ćemo opisati princip rada GAN-ova i metrika koje ćemo nadalje koristiti.

\subsection{Generativne suparničke mreže}
	Prvo dajemo neformalnu ideju. Osnovni cilj je naučiti raspodelu podataka tako da je moguće vršiti uzorkovanje, čime se dobija mogućnost generisanja podataka koji zapravo ne postoje. GAN arhitektura podrazumeva upotrebu dva modela. Prvi je zadužen za učenje pomenute raspodele, dok drugi treba da razlikuje stvarne i generisane podatke. Suparničkim učenjem ova dva modela se stvarna raspodela podataka sve bolje aproksimira.
	
	Neka je $\mathcal{X}=\mathbb{R}^{d \times d}$ prostor slika dimenzija $d\times d$. Bilo koji skup slika možemo predstaviti nekom raspodelom $p_r$ nad $\mathcal{X}$. Skup nad kojim obučavamo model možemo definisati kao prost slučajan uzorak iz raspodele $p_r$. Cilj je naučiti parametrizovanu raspodelu $p_g$ koja aproksimira $p_r$.
	
	GAN se sastoji od \textit{generatora} i \textit{diskriminatora}. Diskriminator posmatramo kao preslikavanje $D: \mathcal{X} \rightarrow [0, 1]$, dok generator kao $G:\mathcal{Z} \rightarrow \mathcal{X}$, gde je $\mathcal{Z}$ latentni prostor. Pomenuti latentni prostor služi za uzorkovanje šuma na osnovu kojeg generator pokušava da generiše elemente raspodele $p_r$. Ako takvo uzorkovanje šuma vršimo iz raspodele $p_z$ definisane nad $\mathcal{Z}$, tada raspodelu $p_g$ možemo definisati kao $G(p_z)$.
	
	Napomenimo male vrednosti diskriminatora odgovaraju generisanim podacima, dok veće stvarnim. Prema tome, generator nastoji generisanju podataka za koje diskriminator daje vrednosti bliske $0$, dok diskriminator za takve ulaze nastoji da se sve viši približi vrednosti $1$.
	
	Obučavanje diskriminatora i generatora se vrši uporedo, usled čega se može videti kao min-max igra. Takav proces se može formalizovati:
	\begin{equation}
	\min_{G}\max_{D}V(D, G) = \mathbb{E}_{x \sim p_r}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))].
	\label{eq:GANClassic}
	\end{equation}
	
	Primetimo da ne postoji ograničenje za izbor modela $D$ i $G$. Međutim, pretpostavljajući njihovu diferencijabilnost i parametrizovanost, obučavanje se može vršiti propagacijom unazad i time u velikoj meri automatizovati.
	
	U početnim iteracijama obučavanja može doći do zasićenja gradijenata \cite{GAN-2014}. Usled lošeg generatora, diskriminator je u stanju vrlo precizno da razlikuje lažne i prave podatke. S tim u vezi, optimizacija iz formule \ref{eq:GANClassic} se može zapisati u numerički pogodnijem obliku:
	\begin{equation}
	\min_{G}\max_{D}V(D, G) = \mathbb{E}_{x \sim p_r}[\log D(x)] - \mathbb{E}_{z \sim p_z}[\log D(G(z))].
	\end{equation}

\subsection{DCGAN}
Generativne suparničke mreže ne podrazumevaju nikakav konkretan model ni za generator ni za diskriminator. S tim u vezi, zavisnosti od domena primene se mogu dizajnirati odgovarajući modeli. Kako se CelebA sastoji od slika, to se opredeljujemo za arhitekturu baziranu na konvolutivnim neuronskim mrežama. Koristićemo DCGAN arhitekturu \cite{DCGAN-2016}, pre svega zbog povoljnog vremena obučavanja.

Prvo ćemo objasniti strukturu generatora ove arhitekture. Sastoji se $5$ blokova koji vrše decimaciju prostornih dimenzija ulaznog tenzora za faktor $2$. Svaki blok se sastoji od konvolutivnog sloja praćenog BN slojem \cite{BN-2015}, osim u poslednjem bloku gde ne postoji sloj normalizacije. Aktivaciona funkcija u svakom konvolutivnom sloju je ReLU \cite{ReLU-2010}, osim u poslednjem gde je sigmoid. Konvolutivni slojevi imaju redom $128, 256, 512, 1024, 1$ kanala. Decimacija se postiže postavljanjem pomeraja konvolutivnog na $2$. Ulazni tenzor je trokanalna RGB slika, koja se prethodno normalizuje sa $\hat{\mu}=0.5$ i $\hat{\sigma}=0.5$.

Generator u odnosu na diskriminator ima inverznu strukturu. Koristi $4$ ekspanziona bloka i transponovane konvolutivne slojeve umesto običnih. Broj kanala u konvolutivnim slojevima je redom $1024, 512, 256, 128, 3$. Pre nego što se latentni šum prosledi prvom konvolutivnom sloju, vrši se projektovanje potpuno povezanim slojem u prostor odgovarajuće dimenzije. Aktivaciona funkcija poslednjeg sloja je hiperbolički tangens.

\subsection{Lipšic neprekidnost generatora}
Pretpostavimo da je diskriminator $D$ neuronska mreža koja za ulaz $x\in \mathcal{X}$ ima sledeći oblik:
\begin{equation}
f(x, \theta) = \prod^{L+1}_{i=0} \beta_{i} + W_{i+1}a_{i},
\end{equation}
gde je $\theta = \{W_i\}^{L+1}_{i=0}$ skup parametara koji se obučavaju, $W_i \in \mathbb{R}^{d_i \times d_{i-1}}$, $W^{L+1} \in \mathbb{R}^{1 \times d_L}$ i $\{a_i\}^{L+1}_{i=0}$ aktivacione funkcije koje se primenjuju član po član.

U \cite{GAN-2014} je dokazano da za fiksiran generator $G$, optimalan diskriminator je oblika:
\begin{equation}
D^{\ast}_{G}(x) = \frac{p_r(x)}{p_r(x) + p_g(x)}=\sigma(f^{\ast}(x)),
\end{equation}
gde je $\sigma$ sigmoid, a $f^{\ast}(x) = \log{p_r(x)} - \log{p_g(x)}$. Tada dobijamo:
\begin{equation}
\nabla_x D^{\ast}_{G}(x) \propto \nabla_x f^{\ast}(x)=\frac{1}{p_r(x)}\nabla_x p_r(x)-\frac{1}{p_g(x)}\nabla_x p_g(x).
\end{equation}
Primetimo da gradijent $\nabla_x f^{\ast}(x)$ nije ograničen. Iz tog razloga dolazi do nepredvidivih oscilacija tokom obučavanja i česte divergencije. Zato je neophodno nametnuti dodatne uslove za $f$. Na osnovu \cite{Lipschitz-2017}, diskriminator obučavamo u prostoru $K$-Lipšic neprekidnih funkcija\footnote{$(\exists K > 0)(\forall x, y \in \mathcal{D}) \norm{f(x) - f(y)} / \norm{x-y} \leq K$}. Drugim rečima, formula \ref{eq:GANClassic} postaje
\begin{equation}
\min_G \max_{\norm{f}_{\operatorname{Lip} \leq K}} V(D, G),
\end{equation}
gde je $\norm{f}_{\operatorname{Lip} \leq K}$ skup svih $K$-Lipšic neprekidnih funkcija u metričkom prostoru $(\mathbb{R}, l_2)$.

Spektralna normalizacija \cite{SN-2018} se zasniva na uslovu da $l_2$ norma svih $W_i$ bude jedinična. Kako je $\norm{W_i}_2 = \sqrt{\lambda_{\text{max}}(W^{T}_{i} W_i)}$, to je neophodno odrediti najveću sopstvenu vrednost matrice $W^{T}_{i} W_i$. Pomenuti postupak je moguće sprovesti iterativno numerički.

U odnosu na standardnu DCGAN implementaciju, u našim eksperimentima je spektralna normalizacija korišćena umesto BN normalizacije isključivo kod diskriminatora.

\subsection{IS}
Adekvatno obučen GAN poseduje sigurnost i varijabilnost. To znači da generator može dati svojstvene podatke, kao i da ravnomerno pokriva čitav kombinatorni prostor.

Prepostavimo da svakoj instanci skupa podataka $x$ možemo pridružiti oznaku $y$. Skup podataka takve oznake ne mora da sadrži, ali ih je moguće uvesti dodatnim modelom $\mathcal{M}$ (kao što je Inception \cite{Inception-2014}) koji je treniran kao klasifikacioni model na nekom drugom skupu podataka (kao što je ImageNet \cite{ImageNet-2014}). Zato možemo posmatrati uslovnu raspodelu $p_{\mathcal{M}}(y|x)$. Marginalna raspodela $p_{\mathcal{M}}(y)$ se dobija kao $\int_{x}p_{\mathcal{M}}(y|x)\text{d}p_g(x)$.

Prema tome, $p_g(y|x)$ treba da odgovara Dirakovoj $\delta$ funkciji, a $p_g(y)$ ravnomernoj raspodeli. Konačno, IS\footnote{eng. \textit{Inception score}} definišemo:
\begin{equation}
\text{IS}(p_g) = \exp(\mathbb{E}_{x \sim p_g}[KL(p_g(y|x)||p_g(y))]),
\end{equation}
gde je $KL$ Kulbek-Lajblerova divergencija.

Ispostavlja se da ova metrika dobro korelira sa ljudskom odlukom \cite{IS-2016}. Međutim, IS ni na koji način ne koristi $p_r$. Takođe, skup podataka nad kojim je $\mathcal{M}$ treniran možda nema ni približno sličnu raspodelu kao $p_r$ usled čega GAN model biva proglašen lošim.

\subsection{FID}
Kao što smo već rekli, ideja obučavanja GAN-a je što bolja aproksimacija $p_r$ raspodelom $p_g$. Ukoliko $p_r$ predstavlja raspodelu podataka iz realnog sveta (poput slika ljudi), tada možemo pretpostaviti ograničenost njenog nosača. U tom slučaju važi:
\begin{equation}
p_r \stackrel{s.s.}{=} p_q \iff (\forall k \in \mathbb{N}) \int_{\mathcal{X}} p_r(x) x^k \text{d}x = \int_{\mathcal{X}} p_g(x) x^k \text{d}x.
\label{eq:probEquality}
\end{equation}
Drugim rečima, jednakost momenata povlači skoro sigurnu jednakost raspodela. U praksi je desnu stranu ekvivalencije \ref{eq:probEquality} skoro nemoguće pokazati. Zato se ona aproksimira za vrednosti do nekog $k$. Mi ćemo aproksimaciju vršiti za $k=2$.

Kako raspodele $p_r$ i $p_g$ nisu eksplicitno poznate, uvodimo operator $\phi$ tako da jednakost $\phi(p_r)$ i $\phi(p_g)$ odgovara jednakosti odgovarajućih raspodela. Kao i kod IS, koristimo Inception model čiji će neki unutrašnji sloj predstavljati operator $\phi$. Inception model obučen nad ImageNet skupu podataka poseduje kvalitetnu aproksimaciju raspodele slika iz stvarnog sveta čiji duboki slojevi poseduju vizuelne karakteristike visokog nivoa. Iz tog razloga, za očekivati je da forsiranjem sličnosti $\phi(p_r)$ i $\phi(p_g)$ postižemo sličnost $p_r$ i $p_g$.

Međutim, raspodele $\phi(p_r)$ i $\phi(p_g)$ takođe nisu eksplicitno poznate. Poznato je da za fiksirane momente prva dva reda normalna raspodela ima maksimalnu entropiju. Zato pretpostavljamo: $\phi(p_r) = \mathcal{N}(\mu_r, \Sigma_r)$ i $\phi(p_g) = \mathcal{N}(\mu_g, \Sigma_g).$ Razliku ovih raspodela merimo Frešeovim rastojanjem:
\begin{equation}
F(\phi(p_r), \phi(p_g)) = \norm{\mu_r - \mu_g} + \text{tr}\left(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2}\right),
\end{equation}
gde je $\text{tr}$ operator traga matrice.

Konačno, definišemo FID\footnote{eng. \textit{Fréchet Inception distance}}$(p_r, p_g)$ kao $F(\phi(p_r), \phi(p_g))$ \cite{FID-2017}. Primetimo da za razliku od IS, FID koristi $p_r$.

\section{Kvantifikovanje obučenosti}

\section{Eksperimenti}

\section{Zaključak}

\begin{thebibliography}{9}
	\bibitem{GAN-2014}
	Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio. Generative Adversarial Nets. \textit{arXiv preprint arXiv:1406.2661}, 2014.
	
	\bibitem{Metrics-2018}
	Qiantong Xu, Gao Huang, Yang Yuan, Chuan Guo, Yu Sun, Felix Wu, Kilian Weinberger. An empirical study on evaluation metrics of generative adversarial networks. \textit{arXiv preprint arXiv:1806.07755}, 2018.
	
	\bibitem{DCGAN-2016}
	Alec Radford, Luke Metz, Soumith Chintala. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. \textit{arXiv preprint arXiv:1511.06434}, 2016.
	
	\bibitem{SN-2018}
	Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida. Spectral Normalization for Generative Adversarial Networks. \textit{arXiv preprint arXiv:1802.05957}, 2018.
	
	\bibitem{WGAN-2017}
	Martin Arjovsky, Soumith Chintala, Léon Bottou. Wasserstein GAN. \textit{arXiv preprint arXiv:1701.07875}, 2017.
	
	\bibitem{GP-2017}
	Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville. Improved Training of Wasserstein GANs. \textit{aXiv preprint arXiv:1704.00028}, 2017.
	
	\bibitem{IS-2016}
	Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen. Improved Techniques for Training GANs. \textit{arXiv preprint arXiv:1606.03498}, 2016.
	
	\bibitem{FID-2017}
	Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernard Nessler. GANs Trained by a Two Time-Scale Update Rule
	Converge to a Local Nash Equilibrium. \textit{NIPS}, 2017.
	
	\bibitem{CelebA-2015}
	Ziwei Liu, Ping Luo, Xiaogang Wang, Xiaoou Tang. Deep Learning Face Attributes in the Wild. \textit{Proceedings of International Conference on Computer Vision (ICCV)}, 2015.
	
	\bibitem{Inception-2014}
	Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich. Going Deeper with Convolutions. \textit{arXiv preprint arXiv:1409.4842}, 2014.
	
	\bibitem{ImageNet-2014}
	Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. \textit{arXiv preprint arXiv:1409.0575}, 2014.
	
	\bibitem{BN-2015}
	Sergey Ioffe, Christian Szegedy. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. \textit{arXiv preprint arXiv:1502.03167}, 2015.
	
	\bibitem{ReLU-2010}
	Vinod Nair, Geoffrey E. Hinton. Rectified linear units improve restricted boltzmann machines. \textit{ICML: Proceedings of the 27th International Conference on International Conference on Machine Learning}, 2010.
	
	\bibitem{Lipschitz-2017}
	Guo-Jun Qi. Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities. \textit{arXiv preprint:arXiv:1701.06264}, 2017.
\end{thebibliography}

\end{document}