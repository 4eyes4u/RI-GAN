\documentclass[12pt, a4paper]{article}
\usepackage[english, croatian]{babel}
\usepackage{authblk}
\usepackage{listings}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{amsfonts}

\usepackage{subfig}
\usepackage{float}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage[%
colorlinks=true,
pdfborder={0 0 0},
linkcolor=red
]{hyperref}

\begin{document}
\date{}
\title{RI-GAN}
\author{Kosta Grujčić, Momčilo Knežević}
\affil{Matematički fakultet }
\maketitle

\begin{abstract}
\end{abstract}

\section{Uvod}

\section{\textit{Related Work}}
U ovom poglavlju ćemo opisati princip rada GAN-ova i metrika koje ćemo nadalje koristiti.

\subsection{Generativne suparničke mreže}
	Prvo dajemo neformalnu ideju. Osnovni cilj je naučiti raspodelu podataka tako da je moguće vršiti uzorkovanje, čime se dobija mogućnost generisanja podataka koji zapravo ne postoje. GAN arhitektura podrazumeva upotrebu dva modela. Prvi je zadužen za učenje pomenute raspodele, dok drugi treba da razlikuje stvarne i generisane podatke. Suparničkim učenjem ova dva modela se stvarna raspodela podataka sve bolje aproksimira.
	
	Neka je $\mathcal{X}=\mathbb{R}^{d \times d}$ prostor slika dimenzija $d\times d$. Bilo koji skup slika možemo predstaviti nekom raspodelom $p_r$ nad $\mathcal{X}$. Skup nad kojim obučavamo model možemo definisati kao prost slučajan uzorak iz raspodele $p_r$. Cilj je naučiti parametrizovanu raspodelu $p_g$ koja aproksimira $p_r$.
	
	GAN se sastoji od \textit{generatora} i \textit{diskriminatora}. Diskriminator posmatramo kao preslikavanje $D: \mathcal{X} \rightarrow [0, 1]$, dok generator kao $G:\mathcal{Z} \rightarrow \mathcal{X}$, gde je $\mathcal{Z}$ latentni prostor. Pomenuti latentni prostor služi za uzorkovanje šuma na osnovu kojeg generator pokušava da generiše elemente raspodele $p_r$. Ako takvo uzorkovanje šuma vršimo iz raspodele $p_z$ definisane nad $\mathcal{Z}$, tada raspodelu $p_g$ možemo definisati kao $G(p_z)$.
	
	Napomenimo male vrednosti diskriminatora odgovaraju generisanim podacima, dok veće stvarnim. Prema tome, generator nastoji generisanju podataka za koje diskriminator daje vrednosti bliske $0$, dok diskriminator za takve ulaze nastoji da se sve viši približi vrednosti $1$.
	
	Obučavanje diskriminatora i generatora se vrši uporedo, usled čega se može videti kao min-max igra. Takav proces se može formalizovati:
	\begin{equation}
	\min_{G}\max_{D}V(D, G) = \mathbb{E}_{x \sim p_r}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))].
	\label{eq:GANClassic}
	\end{equation}
	
	Primetimo da ne postoji ograničenje za izbor modela $D$ i $G$. Međutim, pretpostavljajući njihovu diferencijabilnost i parametrizovanost, obučavanje se može vršiti propagacijom unazad i time u velikoj meri automatizovati.
	
	U početnim iteracijama obučavanja može doći do zasićenja gradijenata \cite{GAN-2014}. Usled lošeg generatora, diskriminator je u stanju vrlo precizno da razlikuje lažne i prave podatke. S tim u vezi, optimizacija iz formule \ref{eq:GANClassic} se može zapisati u numerički pogodnijem obliku:
	\begin{equation}
	\min_{G}\max_{D}V(D, G) = \mathbb{E}_{x \sim p_r}[\log D(x)] - \mathbb{E}_{z \sim p_z}[\log D(G(z))].
	\end{equation}

\subsection{DCGAN}

\subsection{IS}
Adekvatno obučen GAN poseduje sigurnost i varijabilnost. To znači da generator može dati svojstvene podatke, kao i da ravnomerno pokriva čitav kombinatorni prostor.

Prepostavimo da svakoj instanci skupa podataka $x$ možemo pridružiti oznaku $y$. Skup podataka takve oznake ne mora da sadrži, ali ih je moguće uvesti dodatnim modelom $\mathcal{M}$ (kao što je Inception \cite{Inception-2014}) koji je treniran kao klasifikacioni model na nekom drugom skupu podataka (kao što je ImageNet \cite{ImageNet-2014}). Zato možemo posmatrati uslovnu raspodelu $p_{\mathcal{M}}(y|x)$. Marginalna raspodela $p_{\mathcal{M}}(y)$ se dobija kao $\int_{x}p_{\mathcal{M}}(y|x)\text{d}p_g(x)$.

Prema tome, $p_g(y|x)$ treba da odgovara Dirakovoj $\delta$ funkciji, a $p_g(y)$ ravnomernoj raspodeli. Konačno, IS\footnote{eng. \textit{Inception score}} definišemo:
\begin{equation}
\text{IS}(p_g) = \exp(\mathbb{E}_{x \sim p_g}[KL(p_g(y|x)||p_g(y))]),
\end{equation}
gde je $KL$ Kulbek-Lajblerova divergencija.

Ispostavlja se da ova metrika dobro korelira sa ljudskom odlukom \cite{IS-2016}. Međutim, IS ni na koji način ne koristi $p_r$. Takođe, skup podataka nad kojim je $\mathcal{M}$ treniran možda nema ni približno sličnu raspodelu kao $p_r$ usled čega GAN model biva proglašen lošim.

\subsection{FID}
Kao što smo već rekli, ideja obučavanja GAN-a je što bolja aproksimacija $p_r$ raspodelom $p_g$. Ukoliko $p_r$ predstavlja raspodelu podataka iz realnog sveta (poput slika ljudi), tada možemo pretpostaviti ograničenost njenog nosača. U tom slučaju važi:
\begin{equation}
p_r \stackrel{s.s.}{=} p_q \iff (\forall k \in \mathbb{N}) \int_{\mathcal{X}} p_r(x) x^k \text{d}x = \int_{\mathcal{X}} p_g(x) x^k \text{d}x.
\label{eq:probEquality}
\end{equation}
Drugim rečima, jednakost momenata povlači skoro sigurnu jednakost raspodela. U praksi je desnu stranu ekvivalencije \ref{eq:probEquality} skoro nemoguće pokazati. Zato se ona aproksimira za vrednosti do nekog $k$. Mi ćemo aproksimaciju vršiti za $k=2$.

Kako raspodele $p_r$ i $p_g$ nisu eksplicitno poznate, uvodimo operator $\phi$ tako da jednakost $\phi(p_r)$ i $\phi(p_g)$ odgovara jednakosti odgovarajućih raspodela. Kao i kod IS, koristimo Inception model čiji će neki unutrašnji sloj predstavljati operator $\phi$. Inception model obučen nad ImageNet skupu podataka poseduje kvalitetnu aproksimaciju raspodele slika iz stvarnog sveta čiji duboki slojevi poseduju vizuelne karakteristike visokog nivoa. Iz tog razloga, za očekivati je da forsiranjem sličnosti $\phi(p_r)$ i $\phi(p_g)$ postižemo sličnost $p_r$ i $p_g$.

Međutim, raspodele $\phi(p_r)$ i $\phi(p_g)$ takođe nisu eksplicitno poznate. Poznato je da za fiksirane momente prva dva reda normalna raspodela ima maksimalnu entropiju. Zato pretpostavljamo: $\phi(p_r) = \mathcal{N}(\mu_r, \Sigma_r)$ i $\phi(p_g) = \mathcal{N}(\mu_g, \Sigma_g).$ Razliku ovih raspodela merimo Frešeovim rastojanjem:
\begin{equation}
F(\phi(p_r), \phi(p_g)) = ||\mu_r - \mu_g|| + \text{tr}\left(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2}\right),
\end{equation}
gde je $\text{tr}$ operator traga matrice.

Konačno, definišemo FID\footnote{eng. \textit{Fréchet Inception distance}}$(p_r, p_g)$ kao $F(\phi(p_r), \phi(p_g))$ \cite{FID-2017}. Primetimo da za razliku od IS, FID koristi $p_r$.

\section{Kvantifikovanje obučenosti}

\section{Eksperimenti}

\section{Zaključak}

\begin{thebibliography}{9}
	\bibitem{GAN-2014}
	Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio. Generative Adversarial Nets. \textit{arXiv preprint arXiv:1406.2661}, 2014.
	
	\bibitem{Metrics-2018}
	Qiantong Xu, Gao Huang, Yang Yuan, Chuan Guo, Yu Sun, Felix Wu, Kilian Weinberger. An empirical study on evaluation metrics of generative adversarial networks. \textit{arXiv preprint arXiv:1806.07755}, 2018.
	
	\bibitem{DCGAN-2016}
	Alec Radford, Luke Metz, Soumith Chintala. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. \textit{arXiv preprint arXiv:1511.06434}, 2016.
	
	\bibitem{SN-2018}
	Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida. Spectral Normalization for Generative Adversarial Networks. \textit{arXiv preprint arXiv:1802.05957}, 2018.
	
	\bibitem{WGAN-2017}
	Martin Arjovsky, Soumith Chintala, Léon Bottou. Wasserstein GAN. \textit{arXiv preprint arXiv:1701.07875}, 2017.
	
	\bibitem{GP-2017}
	Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville. Improved Training of Wasserstein GANs. \textit{aXiv preprint arXiv:1704.00028}, 2017.
	
	\bibitem{IS-2016}
	Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen. Improved Techniques for Training GANs. \textit{arXiv preprint arXiv:1606.03498}, 2016.
	
	\bibitem{FID-2017}
	Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernard Nessler. GANs Trained by a Two Time-Scale Update Rule
	Converge to a Local Nash Equilibrium. \textit{NIPS}, 2017.
	
	\bibitem{CelebA-2015}
	Ziwei Liu, Ping Luo, Xiaogang Wang, Xiaoou Tang. Deep Learning Face Attributes in the Wild. \textit{Proceedings of International Conference on Computer Vision (ICCV)}, 2015.
	
	\bibitem{Inception-2014}
	Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich. Going Deeper with Convolutions. \textit{arXiv preprint arXiv:1409.4842}, 2014.
	
	\bibitem{ImageNet-2014}
	Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. \textit{arXiv preprint arXiv:1409.0575}, 2014.
\end{thebibliography}

\end{document}